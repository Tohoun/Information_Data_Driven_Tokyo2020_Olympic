{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of data\n",
    "This section will consist to exatct and transform data to be ready to upload in data warehouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all needed packages or modules\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session, declarative_base\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of spark Session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extraction of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all data from your device or github. \n",
    "# In my case i downlad data in my device then i precise the path of the folder in my device\n",
    "path1 =\"E:/Learning/repos/Information_Data_Driven_Tokyo2020_Olympic/\"\n",
    "\n",
    "## Althletes data\n",
    "url1 =path1+\"data/raw/athletes.csv\"\n",
    "df0_athletes = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\",True)\\\n",
    "                            .load(url1)\n",
    "\n",
    "## Coaches data\n",
    "url2 =path1+\"data/raw/coaches.csv\"\n",
    "df0_coaches = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\",True)\\\n",
    "                            .load(url2)\n",
    "\n",
    "## Medals data\n",
    "url3 =path1+\"data/raw/medals.csv\"\n",
    "df0_medals = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\",True)\\\n",
    "                            .load(url3)\n",
    "\n",
    "## country data\n",
    "url4 =path1+\"data/raw/all.csv\"\n",
    "df0_countries = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\",True)\\\n",
    "                            .load(url4)\n",
    "\n",
    "## medals types data\n",
    "url5 =path1+\"data/raw/medals_type.csv\"\n",
    "df0_medals_type = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\",True)\\\n",
    "                            .load(url5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need all columns in each dataset and also to avoid redondance data in our warehouse we need to code somme data like names of althletes reapet in athletes data and medals also the discipline's name repeat in all 3 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns need in Athletes dataset\n",
    "df1_athletes = df0_athletes[\"name\",\"gender\",\"birth_date\",\"country_code\",\"discipline_code\"]\n",
    "\n",
    "## Columns need in Coaches dataset\n",
    "df1_coaches = df0_coaches[\"name\",\"gender\",\"birth_date\",\"country_code\",\"discipline\",\"function\"]\n",
    "\n",
    "## Columns need in Medals dataset\n",
    "df1_medals = df0_medals[\"medal_code\",\"medal_date\",\"athlete_name\",\"country_code\",\"discipline_code\",\"event\"]\n",
    "\n",
    "## Columns need in countries dataset\n",
    "df1_countries = df0_countries[\"name\",\"alpha-3\",\"region\",\"sub-region\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- birth_date: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- discipline_code: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- birth_date: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- discipline: string (nullable = true)\n",
      " |-- function: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- medal_code: string (nullable = true)\n",
      " |-- medal_date: string (nullable = true)\n",
      " |-- athlete_name: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- discipline_code: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Structure of dataframe before convert\n",
    "df1_athletes.printSchema()\n",
    "df1_coaches.printSchema()\n",
    "df1_medals.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tranformation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert birth_date from string to date\n",
    "df1_athletes = df1_athletes.withColumn(\"birth_date\",to_date(col(\"birth_date\"),\"yyyy-MM-dd\"))\n",
    "df1_coaches = df1_coaches.withColumn(\"birth_date\",to_date(col(\"birth_date\"),\"yyyy-MM-dd\"))\n",
    "df1_medals = df1_medals.withColumn(\"medal_date\",split(df1_medals[\"medal_date\"],\" \").getItem(0))\\\n",
    "                        .withColumn(\"medal_date\",to_date(col(\"medal_date\"),\"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- birth_date: date (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- discipline_code: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- birth_date: date (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- discipline: string (nullable = true)\n",
      " |-- function: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- medal_code: string (nullable = true)\n",
      " |-- medal_date: date (nullable = true)\n",
      " |-- athlete_name: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- discipline_code: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Structure of dataframe after convert\n",
    "df1_athletes.printSchema()\n",
    "df1_coaches.printSchema()\n",
    "df1_medals.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renamed some columns for countries dataset\n",
    "df1_countries= df1_countries.withColumnRenamed(\"alpha-3\",\"country_code\")\\\n",
    "                            .withColumnRenamed(\"region\",\"continent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the engine\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:1991@localhost:5432/OLYMPIC2020\")\n",
    "# Initialize the session\n",
    "session = Session(engine)\n",
    "# Initialize the declarative base\n",
    "Base = declarative_base()\n",
    "# conn_string = 'postgres://postgres:1991@localhost/OLYMPIC2020'\n",
    "# db = create_engine(conn_string)\n",
    "# conn = db.connect()\n",
    "#conn = psycopg2.connect(database=\"OLYMPIC2020\", user='postgres', password='1991', host='localhost', port='5432')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' url = \"jdbc:postgresql://localhost:5432/OLYMPIC2020\"\\n\\nproperties = {\\n    \"user\": \"postgres\",\\n    \"password\": \"*******\",\\n    \"driver\": \"org.postgresql.Driver\"\\n}\\ndf0_medals_type.write.jdbc(url=url, table=\"r_medals\", mode=\"overwrite\", properties=properties) '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" url = \"jdbc:postgresql://localhost:5432/OLYMPIC2020\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"*******\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "df0_medals_type.write.jdbc(url=url, table=\"r_medals\", mode=\"overwrite\", properties=properties) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_values(conn, df, table):\n",
    "  \n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "  \n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the dataframe is inserted\")\n",
    "    cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
